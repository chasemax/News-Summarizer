{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting News Source The Hacker News\n",
      "Getting article information Google Teams Up with Ecosystem Partners to Enhance Security of SoC Processors\n",
      "Getting article information How to Tackle the Top SaaS Challenges of 2023\n",
      "Getting article information How to Use AI in Cybersecurity and Avoid Being Trapped\n",
      "Getting article information CISA Sounds Alarm on Cybersecurity Threats Amid Russia's Invasion Anniversary\n",
      "Getting article information Even Top-Ranked Android Apps in Google Play Store Provide Misleading Data Safety Labels\n",
      "Getting article information Hackers Using Trojanized macOS Apps to Deploy Evasive Cryptocurrency Mining Malware\n",
      "Getting article information Experts Sound Alarm Over Growing Attacks Exploiting Zoho ManageEngine Products\n",
      "Getting article information The Secret Vulnerability Finance Execs are Missing\n",
      "Getting article information New Hacking Cluster 'Clasiopa' Targeting Materials Research Organizations in Asia\n",
      "Getting article information Lazarus Group Likely Using New WinorDLL64 Backdoor to Exfiltrate Sensitive Data\n",
      "Getting article information New S1deload Malware Hijacking Users' Social Media Accounts and Mining Cryptocurrency\n",
      "Getting article information Python Developers Warned of Trojanized PyPI Packages Mimicking Popular Libraries\n",
      "Getting article information Apple Warns of 3 New Vulnerabilities Affecting iPhone, iPad, and Mac Devices\n",
      "Getting article information Attackers Flood NPM Repository with Over 15,000 Spam Packages Containing Phishing Links\n",
      "Getting article information 3 Steps to Automate Your Third-Party Risk Management Program\n",
      "Getting article information Hydrochasma: New Threat Actor Targets Shipping Companies and Medical Labs in Asia\n",
      "Getting article information Threat Actors Adopt Havoc Framework for Post-Exploitation in Targeted Attacks\n",
      "Getting article information Gcore Thwarts Massive 650 Gbps DDoS Attack on Free Plan Client\n",
      "Getting article information U.S. Cybersecurity Agency CISA Adds Three New Vulnerabilities in KEV Catalog\n",
      "Getting article information VMware Patches Critical Vulnerability in Carbon Black App Control Product\n",
      "Getting article information MyloBot Botnet Spreading Rapidly Worldwide: Infecting Over 50,000 Devices Daily\n",
      "Getting article information The Future of Network Security: Predictive Analytics and ML-Driven Solutions\n",
      "Getting article information Researchers Discover Numerous Samples of Information Stealer 'Stealc' in the Wild\n",
      "Getting article information Coinbase Employee Falls for SMS Scam in Cyber Attack, Limited Data Exposed\n",
      "Getting article information Researchers Warn of ReverseRAT Backdoor Targeting Indian Government Agencies\n",
      "Getting article information Norway Seizes $5.84 Million in Cryptocurrency Stolen by Lazarus Hackers\n",
      "Getting article information How to Detect New Threats via Suspicious Activities\n",
      "Getting article information Google Reveals Alarming Surge in Russian Cyber Attacks Against Ukraine\n",
      "Getting article information Cyber Espionage Group Earth Kitsune Deploys WhiskerSpy Backdoor in Latest Attacks\n",
      "Getting article information Samsung Introduces New Feature to Protect Users from Zero-Click Malware Attacks\n",
      "Getting article information Fortinet Issues Patches for 40 Flaws Affecting FortiWeb, FortiOS, FortiNAC, and FortiProxy\n",
      "Getting article information Twitter Limits SMS-Based 2-Factor Authentication to Blue Subscribers Only\n",
      "Getting article information GoDaddy Discloses Multi-Year Security Breach Causing Malware Installations and Source Code Theft\n",
      "Getting article information Experts Warn of RambleOn Android Malware Targeting South Korean Journalists\n",
      "Getting article information ⚡Top Cybersecurity News Stories This Week — Cybersecurity Newsletter\n",
      "Getting article information Armenian Entities Hit by New Version of OxtaRAT Spying Tool\n",
      "Getting article information New Mirai Botnet Variant 'V3G4' Exploiting 13 Flaws to Target Linux and IoT Devices\n",
      "Getting article information Critical RCE Vulnerability Discovered in ClamAV Open Source Antivirus Software\n",
      "Getting article information Researchers Hijack Popular NPM Package with Millions of Downloads\n",
      "Getting article information Researchers Link SideWinder Group to Dozens of Targeted Attacks in Multiple Countries\n",
      "Getting article information Hackers Using Google Ads to Spread FatalRAT Malware Disguised as Popular Apps\n",
      "Getting article information Researchers Warn of Critical Security Bugs in Schneider Electric Modicon PLCs\n",
      "Getting article information Breaking the Security \"Black Box\" in DBs, Data Warehouses and Data Lakes\n",
      "Getting article information New Threat Actor WIP26 Targeting Telecom Service Providers in the Middle East\n",
      "Getting article information ESXiArgs Ransomware Hits Over 500 New Targets in European Countries\n",
      "Getting article information North Korea's APT37 Targeting Southern Counterpart with New M2RAT Malware\n",
      "Getting article information Webinar — A MythBusting Special: 9 Myths about File-based Threats\n",
      "Getting article information Financially Motivated Threat Actor Strikes with New Ransomware and Clipper Malware\n",
      "Getting article information Regular Pen Testing Is Key to Resolving Conflict Between SecOps and DevOps\n",
      "Getting article information Experts Warn of 'Beep' - A New Evasive Malware That Can Fly Under the Radar\n",
      "Getting News Source Krebs on Security\n",
      "Getting article information Who’s Behind the Botnet-Based Service BHProxies?\n",
      "Getting article information New Protections for Food Benefits Stolen by Skimmers\n",
      "Getting article information Microsoft Patch Tuesday, February 2023 Edition\n",
      "Getting article information U.S., U.K. Sanction 7 Men Tied to Trickbot Hacking Group\n",
      "Getting article information KrebsOnSecurity in Upcoming Hulu Series on Ashley Madison Breach\n",
      "Getting article information Finland’s Most-Wanted Hacker Nabbed in France\n",
      "Getting article information Experian Glitch Exposing Credit Files Lasted 47 Days\n",
      "Getting article information Administrator of RSOCKS Proxy Botnet Pleads Guilty\n",
      "Getting article information New T-Mobile Breach Affects 37 Million Accounts\n",
      "Getting article information Thinking of Hiring or Running a Booter Service? Think Again.\n",
      "Getting News Source Threatpost\n",
      "Getting article information Student Loan Breach Exposes 2.5M Records\n",
      "Getting article information Watering Hole Attacks Push ScanBox Keylogger\n",
      "Getting article information Tentacles of ‘0ktapus’ Threat Group Victimize 130 Firms\n",
      "Getting article information Ransomware Attacks are on the Rise\n",
      "Getting article information Cybercriminals Are Selling Access to Chinese Surveillance Cameras\n",
      "Getting article information Twitter Whistleblower Complaint: The TL;DR Version\n",
      "Getting article information Firewall Bug Under Active Attack Triggers CISA Warning\n",
      "Getting article information Fake Reservation Links Prey on Weary Travelers\n",
      "Getting article information iPhone Users Urged to Update to Patch 2 Zero-Days\n",
      "Getting article information Google Patches Chrome’s Fifth Zero-Day of the Year\n",
      "Getting News Source Naked Security\n",
      "Getting article information S3 Ep123: Crypto company compromise kerfuffle [Audio + Text]\n",
      "Getting article information NPM JavaScript packages abused to create scambait links in bulk\n",
      "Getting article information Coinbase breached by social engineers, employee data stolen\n",
      "Getting article information Twitter tells users: Pay up if you want to keep using insecure 2FA\n",
      "Getting article information GoDaddy admits: Crooks hit us with malware, poisoned customer websites\n",
      "Getting article information S3 Ep122: Stop calling every breach “sophisticated”! [Audio + Text]\n",
      "Getting article information Microsoft Patch Tuesday: 36 RCE bugs, 3 zero-days, 75 CVEs\n",
      "Getting article information Apple fixes zero-day spyware implant bug – patch now!\n",
      "Getting article information Serious Security: GnuTLS follows OpenSSL, fixes timing attack bug\n",
      "Getting article information Reddit admits it was hacked and data stolen, says “Don’t panic”\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "\n",
    "# This function returns whether or not a particular tag is visible to the viewer of a web page\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# This function extracts the readable content text from a webpage\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.find_all('p', text=True)\n",
    "    visible_texts = filter(tag_visible, texts)\n",
    "    return u\" \".join(t.get_text() for t in visible_texts)\n",
    "\n",
    "# This is a list of the RSS feeds we are subscribing to for security news\n",
    "newsSources = {\n",
    "    'The Hacker News': 'https://feeds.feedburner.com/TheHackersNews?format=xml',\n",
    "    #'Graham Cluley': 'https://www.grahamcluley.com/feed/',\n",
    "    'Krebs on Security': 'http://krebsonsecurity.com/feed/',\n",
    "    'Threatpost': 'https://threatpost.com/feed/',\n",
    "    'Naked Security': 'https://nakedsecurity.sophos.com/feed/'\n",
    "}\n",
    "\n",
    "articleTexts = []\n",
    "\n",
    "for title, source in newsSources.items():\n",
    "\n",
    "    print(\"Getting News Source\", title)\n",
    "    # For every news source, we get the RSS feed. \n",
    "    feed = feedparser.parse(source)\n",
    "\n",
    "    for article in feed['items']:\n",
    "\n",
    "        print(\"Getting article information\", article['title'])\n",
    "        #For every article in the feed, we open the web page\n",
    "        html = urllib.request.urlopen(article['link']).read()\n",
    "\n",
    "        #Then we extract the text from the web page and put it in an object\n",
    "        articleTexts.append({\n",
    "            \"title\" : article['title'],\n",
    "            \"body\" : text_from_html(html)\n",
    "        })\n",
    "        #break # Remove to loop through all sources; currently we just get one article from each source\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_cluster(data, num_clusters=None, svd_dimensions=300):\n",
    "    \n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    from sklearn.metrics import calinski_harabasz_score\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    #Vectorize the data, using english stop words\n",
    "    vectorizer = TfidfVectorizer(min_df=2, max_df=0.3, stop_words='english', use_idf=True)\n",
    "    trans_data = vectorizer.fit_transform(data)\n",
    "    print(\"Transformed data contains \" + str(trans_data.shape[0]) + \" with \" + str(trans_data.shape[1]) + \" features \")\n",
    "\n",
    "    #SVD and Normalize the data to reduce the number of features we need to train on and improve training time\n",
    "    svd = TruncatedSVD(svd_dimensions)\n",
    "    pipe = make_pipeline(svd, Normalizer(copy=False))\n",
    "    reduced_data = pipe.fit_transform(trans_data)\n",
    "\n",
    "    #Cluster the data\n",
    "\n",
    "    km = None\n",
    "    final_num_clusters = 0\n",
    "    final_labels = []\n",
    "\n",
    "    if (num_clusters == None):\n",
    "\n",
    "        # They want us to pick the number of clusters\n",
    "        all_ch_scores = []\n",
    "        for n in range(2, 20):\n",
    "            km = KMeans(n_clusters=n, init='k-means++', max_iter=100, random_state=0)\n",
    "            labels = km.fit_predict(reduced_data)\n",
    "            ch_score = calinski_harabasz_score(reduced_data, labels)\n",
    "            all_ch_scores.append((n, ch_score))\n",
    "        \n",
    "        max_ch_score = max(all_ch_scores, key=lambda x: x[1])\n",
    "        print(\"The Best CH score was \" + str(max_ch_score[1]) + \" for \" + str(max_ch_score[0]) + \" clusters.\")\n",
    "        final_num_clusters = max_ch_score[0]\n",
    "        km = KMeans(n_clusters=final_num_clusters, init='k-means++', max_iter=100, random_state=0)\n",
    "        final_labels = km.fit_predict(reduced_data)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # They've chosen the number\n",
    "        final_num_clusters = num_clusters\n",
    "        km = KMeans(n_clusters=final_num_clusters, init='k-means++', max_iter=100, random_state=0)\n",
    "        final_labels = km.fit_predict(reduced_data)\n",
    "        ch_score = calinski_harabasz_score(reduced_data, labels)\n",
    "        \n",
    "\n",
    "    #Evaluate manually\n",
    "    print(\"\\nMost discriminative words per cluster:\")\n",
    "    original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "    order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(final_num_clusters):\n",
    "        print(\"Cluster \" + str(i) + \": \")\n",
    "        cl_terms = \"\"\n",
    "        for ind in order_centroids[i, :50]:\n",
    "            cl_terms += terms[ind] + \" \"\n",
    "        print(cl_terms + \"\\n\")\n",
    "\n",
    "    labeled_data = list(zip(data, final_labels))\n",
    "    return labeled_data, final_num_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data contains 80 with 2652 features \n",
      "The Best CH score was 2.1753903711164346 for 3 clusters.\n",
      "\n",
      "Most discriminative words per cluster:\n",
      "Cluster 0: \n",
      "content sponsored threatpost group written sponsor community share article scanbox ib cameras devices researchers thousands pan insight campaigns travel os subject wrote contribution audience editorial edited strives infosec july team participate commentary quality voice advertiser matter highest trusted opportunity insider topics prolific experts according patch campaign objective writing editing creates \n",
      "\n",
      "Cluster 1: \n",
      "fraud credit people ai account posts card spam service russia development cyber carding badguy stolen russian accounts cards uses money servers transactions id network facebook government suspected series breach pc testing twitter cloud number criminal don nation bitcoin services android ransomware bad image followers ransom way early blue alternative solutions \n",
      "\n",
      "Cluster 2: \n",
      "apps files server google execution remote c2 actors app software actor tools vulnerabilities execute attacker commands godaddy cve service don source user vulnerability sensitive machine password threats victim flaws target means bug devices crooks coinbase command behavior apple know updates versions chain 2fa arbitrary reddit researchers zero credentials systems patches \n",
      "\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxfi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "articleBodies = [article['body'] for article in articleTexts]\n",
    "random.shuffle(articleBodies)\n",
    "\n",
    "labeled_articles, clusters = train_and_eval_cluster(articleBodies)\n",
    "labeled_articles[0]\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "updated_punctuation = punctuation + \"”\"\n",
    "\n",
    "def extraction_summarize(text, target_length):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in updated_punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = word_frequencies[word] / max_frequency\n",
    "    sentence_tokens = [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "    sentence_tuples = [(sentence, score) for sentence, score in sentence_scores.items()]\n",
    "    sentence_tuples.sort(key = lambda x: x[1], reverse=True)\n",
    "    summary = \"\"\n",
    "\n",
    "    sentence_number = 0\n",
    "\n",
    "    while (len(summary.split()) < target_length):\n",
    "        summary += sentence_tuples[sentence_number][0].text\n",
    "        sentence_number += 1\n",
    "        \n",
    "    return summary\n",
    "\n",
    "# This function performs abstraction summarization on a given text, using neural networks to \n",
    "# write a whole new summary for the given text.\n",
    "def abstraction_summarize(original_text):\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    summary_text = summarizer(original_text, min_length = 100)\n",
    "    return summary_text[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TA423’s attacks began with phishing emails, with such titles as “Sick Leave,” “User Research” and “Request Cooperation” The personal information that was accessed in the Nelnet breach “has potential to be leveraged in future social engineering and phishing campaigns . Lockbit was by far the most prolific ransomware gang in July, behind 62 attacks, researchers have determined . The authors of the report could only speculate that “Chinese threat groups such as MISSION2025/APT41, APT10 and its affiliates, as well as unknown Russian threat actor groups could potentially exploit vulnerabilities in these devices .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " T-Mobile is saying that this time “no customer payment card data, passwords, Social Security numbers, driver’s license or other government ID numbers were exposed.” Hardly reassuring, since this info was leaked in the previous two massive data breaches . Programmers are basically a bunch of tools (if not toolbags) who use tools and services to provide paid programming services of building tools and creating services for other tools . It may or may be related to the MOTW “mark of the web” default popup “warning” being bypassed trivially on files downloaded from the internet .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sophos Home protects every Mac and PC in your home . In this bug, firing the same encrypted message over and over again at a server, but modifying the padding at the end of the data to make the data invalid, and thus provoking some sort of unpredictable behaviour . All I’m hoping is that, given that there’s not much we can advise people about now because we have no indicators of compromise, and we don’t even know whether, at this remove, GoDaddy has been able to come up with what people could go and look for .\n"
     ]
    }
   ],
   "source": [
    "# Summarize each topic\n",
    "\n",
    "for topic in range(clusters):\n",
    "    text_body = \" \"\n",
    "    \n",
    "    for article, label in labeled_articles:\n",
    "        if label == topic:\n",
    "            text_body += article + \" \"\n",
    "    \n",
    "    print(abstraction_summarize(extraction_summarize(text_body, 600)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "777c797f3d76ce7bff5edf599e7a6aa4adabe4f1940962bf4a5a933b2d8fa9f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
